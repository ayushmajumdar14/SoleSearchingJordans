{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping model: Air Jordan 1 Bred 1985\n",
      "  -> Found 90 results for Air Jordan 1 Bred 1985\n",
      "\n",
      "Scraping model: Air Jordan 1 Chicago 1985\n",
      "  -> Found 90 results for Air Jordan 1 Chicago 1985\n",
      "\n",
      "Scraping model: Air Jordan 2 OG 1986\n",
      "  -> Found 90 results for Air Jordan 2 OG 1986\n",
      "\n",
      "Scraping model: Air Jordan 3 Black Cement 1988\n",
      "  -> Found 62 results for Air Jordan 3 Black Cement 1988\n",
      "\n",
      "Scraping model: Air Jordan 4 Fire Red 1989\n",
      "  -> Found 90 results for Air Jordan 4 Fire Red 1989\n",
      "\n",
      "Scraping model: Air Jordan 5 Grape 1990\n",
      "  -> Found 90 results for Air Jordan 5 Grape 1990\n",
      "\n",
      "Scraping model: Air Jordan 6 Infrared 1991\n",
      "  -> Found 90 results for Air Jordan 6 Infrared 1991\n",
      "\n",
      "Scraping model: Air Jordan 7 Olympic 1992\n",
      "  -> Found 90 results for Air Jordan 7 Olympic 1992\n",
      "\n",
      "Scraping model: Air Jordan 8 Aqua 1993\n",
      "  -> Found 90 results for Air Jordan 8 Aqua 1993\n",
      "\n",
      "Scraping model: Air Jordan 9 Space Jam 1994\n",
      "  -> Found 90 results for Air Jordan 9 Space Jam 1994\n",
      "\n",
      "Scraping model: Air Jordan 10 Steel 1994\n",
      "  -> Found 90 results for Air Jordan 10 Steel 1994\n",
      "\n",
      "Scraping model: Air Jordan 11 Concord 1995\n",
      "  -> Found 90 results for Air Jordan 11 Concord 1995\n",
      "\n",
      "Scraping model: Air Jordan 12 Flu Game 1997\n",
      "  -> Found 90 results for Air Jordan 12 Flu Game 1997\n",
      "\n",
      "Scraping model: Air Jordan 13 Bred 1998\n",
      "  -> Found 90 results for Air Jordan 13 Bred 1998\n",
      "\n",
      "Scraping model: Air Jordan 14 Last Shot 1999\n",
      "  -> Found 90 results for Air Jordan 14 Last Shot 1999\n",
      "\n",
      "Scraping model: Air Jordan 1 Retro Chicago 2013\n",
      "  -> Found 90 results for Air Jordan 1 Retro Chicago 2013\n",
      "\n",
      "Scraping model: Air Jordan 3 Retro Black Cement 2011\n",
      "  -> Found 90 results for Air Jordan 3 Retro Black Cement 2011\n",
      "\n",
      "Scraping model: Air Jordan 4 Retro Bred 2019\n",
      "  -> Found 90 results for Air Jordan 4 Retro Bred 2019\n",
      "\n",
      "Scraping model: Air Jordan 5 Retro Raging Bull\n",
      "  -> Found 90 results for Air Jordan 5 Retro Raging Bull\n",
      "\n",
      "Scraping model: Air Jordan 6 Travis Scott\n",
      "  -> Found 90 results for Air Jordan 6 Travis Scott\n",
      "\n",
      "Total scraped listings: 1772\n",
      "                    model                                              title  \\\n",
      "0  Air Jordan 1 Bred 1985  Original vintage 1985 Jordan 1 Bred Size 9 in ...   \n",
      "1  Air Jordan 1 Bred 1985      Size 10 - Jordan 1 Retro OG High Banned, Bred   \n",
      "2  Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "3  Air Jordan 1 Bred 1985       Jordan 1 Retro OG High Patent Bred - Size 13   \n",
      "4  Air Jordan 1 Bred 1985  Nike Air Jordan 1 Retro Banned 'Bred' 2016 Siz...   \n",
      "5  Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "6  Air Jordan 1 Bred 1985                           2016 ‚ÄúBred‚Äù Air Jordan 1   \n",
      "7  Air Jordan 1 Bred 1985                           2016 ‚ÄúBred‚Äù Air Jordan 1   \n",
      "8  Air Jordan 1 Bred 1985                          Jordan 1 High Patent Bred   \n",
      "9  Air Jordan 1 Bred 1985  Size 13 - Jordan 1 Retro OG High Patent Bred u...   \n",
      "\n",
      "     price                                               link authenticity  \\\n",
      "0  $800.00  https://www.ebay.com/itm/135429488780?_skw=Air...                \n",
      "1  $260.00  https://www.ebay.com/itm/226645169511?_skw=Air...                \n",
      "2  $180.00  https://www.ebay.com/itm/146435708936?_skw=Air...                \n",
      "3  $170.00  https://www.ebay.com/itm/405634081981?_skw=Air...                \n",
      "4  $174.02  https://www.ebay.com/itm/387464649949?_skw=Air...                \n",
      "5  $240.00  https://www.ebay.com/itm/256792015633?_skw=Air...                \n",
      "6  $239.99  https://www.ebay.com/itm/226641824337?_skw=Air...                \n",
      "7  $239.99  https://www.ebay.com/itm/226607613459?_skw=Air...                \n",
      "8  $180.00  https://www.ebay.com/itm/286382936757?_skw=Air...                \n",
      "9  $130.00  https://www.ebay.com/itm/226628841812?_skw=Air...                \n",
      "\n",
      "  sell_date  \n",
      "0      None  \n",
      "1      None  \n",
      "2      None  \n",
      "3      None  \n",
      "4      None  \n",
      "5      None  \n",
      "6      None  \n",
      "7      None  \n",
      "8      None  \n",
      "9      None  \n",
      "Final DataFrame saved as final_jordan_data.csv\n",
      "                     model                                              title  \\\n",
      "0   Air Jordan 1 Bred 1985  Original vintage 1985 Jordan 1 Bred Size 9 in ...   \n",
      "1   Air Jordan 1 Bred 1985      Size 10 - Jordan 1 Retro OG High Banned, Bred   \n",
      "2   Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "3   Air Jordan 1 Bred 1985       Jordan 1 Retro OG High Patent Bred - Size 13   \n",
      "4   Air Jordan 1 Bred 1985  Nike Air Jordan 1 Retro Banned 'Bred' 2016 Siz...   \n",
      "5   Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "6   Air Jordan 1 Bred 1985                           2016 ‚ÄúBred‚Äù Air Jordan 1   \n",
      "7   Air Jordan 1 Bred 1985                           2016 ‚ÄúBred‚Äù Air Jordan 1   \n",
      "8   Air Jordan 1 Bred 1985                          Jordan 1 High Patent Bred   \n",
      "9   Air Jordan 1 Bred 1985  Size 13 - Jordan 1 Retro OG High Patent Bred u...   \n",
      "10  Air Jordan 1 Bred 1985  Nike Air Jordan 1 Retro High OG Shadow 555088-...   \n",
      "11  Air Jordan 1 Bred 1985  Jordan 1 Mid Banned 2020 Size 13 554724-074 Bl...   \n",
      "12  Air Jordan 1 Bred 1985  Nike Jordan 1 Retro High ‚ÄúBred Banned‚Äù 2016 Sz 10   \n",
      "13  Air Jordan 1 Bred 1985  Size 10 - Jordan 1 Retro OG High Shadow !No in...   \n",
      "14  Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "15  Air Jordan 1 Bred 1985                Air Jordan 1 High Patent Bred Sz 13   \n",
      "16  Air Jordan 1 Bred 1985  üö®Jordan 1 Retro High 85 Varsity Red Sz 12 Neve...   \n",
      "17  Air Jordan 1 Bred 1985             Size 11 - Air Jordan 1 Retro 1994 Bred   \n",
      "18  Air Jordan 1 Bred 1985              Air Jordan 1 Bred Banned 2016 Size 10   \n",
      "19  Air Jordan 1 Bred 1985      Size 10 - Jordan 1 Retro OG High Banned, Bred   \n",
      "20  Air Jordan 1 Bred 1985  Size 12 - Jordan 1 Retro High 85 Varsity Red 2020   \n",
      "21  Air Jordan 1 Bred 1985  Nike Air Jordan 1 Mid Banned Black Red White 5...   \n",
      "22  Air Jordan 1 Bred 1985       Size 10 - Jordan 1 Retro OG High Shadow VNDS   \n",
      "23  Air Jordan 1 Bred 1985  Air Jordan 1 Retro High OG Size 10 Banned, Bre...   \n",
      "24  Air Jordan 1 Bred 1985      Size 10 - Jordan 1 Retro OG High Banned, Bred   \n",
      "25  Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "26  Air Jordan 1 Bred 1985            Size 10 - Jordan 1 Retro OG High Shadow   \n",
      "27  Air Jordan 1 Bred 1985      Size 10 - Jordan 1 Retro OG High Banned, Bred   \n",
      "28  Air Jordan 1 Bred 1985   Jordan 1 Retro High Bred Banned 2016, US Size 10   \n",
      "29  Air Jordan 1 Bred 1985  DS sz 13 Nike Air Jordan 1 Mid Retro Banned 55...   \n",
      "30  Air Jordan 1 Bred 1985  1985 Nike Air Jordan 1 Bred Size 10.5 Black Re...   \n",
      "31  Air Jordan 1 Bred 1985  Original 1985 Air Jordan 1 High Vintage  Nike ...   \n",
      "32  Air Jordan 1 Bred 1985  Air Jordan 1 Retro High OG Patent Bred - Size ...   \n",
      "33  Air Jordan 1 Bred 1985             Jordan 1 Retro High Bred Banned (2016)   \n",
      "34  Air Jordan 1 Bred 1985  Size 10 Nike Air Jordan 1 Retro OG High Banned...   \n",
      "35  Air Jordan 1 Bred 1985            1985 OG Nike Air Jordan 1 Bred us11 TY1   \n",
      "36  Air Jordan 1 Bred 1985       Size 13 - Jordan 1 Retro OG High Patent Bred   \n",
      "37  Air Jordan 1 Bred 1985  Nike Air Jordan 1 high Patent Bred Size 13 Men...   \n",
      "38  Air Jordan 1 Bred 1985                 Size 13 - Jordan 1 Mid Banned 2020   \n",
      "39  Air Jordan 1 Bred 1985  Nike Air Jordan 1 Mid Banned Black Red White 5...   \n",
      "\n",
      "               price                                               link  \\\n",
      "0            $800.00  https://www.ebay.com/itm/135429488780?_skw=Air...   \n",
      "1            $260.00  https://www.ebay.com/itm/226645169511?_skw=Air...   \n",
      "2            $180.00  https://www.ebay.com/itm/146435708936?_skw=Air...   \n",
      "3            $170.00  https://www.ebay.com/itm/405634081981?_skw=Air...   \n",
      "4            $174.02  https://www.ebay.com/itm/387464649949?_skw=Air...   \n",
      "5            $240.00  https://www.ebay.com/itm/256792015633?_skw=Air...   \n",
      "6            $239.99  https://www.ebay.com/itm/226641824337?_skw=Air...   \n",
      "7            $239.99  https://www.ebay.com/itm/226607613459?_skw=Air...   \n",
      "8            $180.00  https://www.ebay.com/itm/286382936757?_skw=Air...   \n",
      "9            $130.00  https://www.ebay.com/itm/226628841812?_skw=Air...   \n",
      "10           $249.99  https://www.ebay.com/itm/135595150612?_skw=Air...   \n",
      "11            $65.00  https://www.ebay.com/itm/316417856973?_skw=Air...   \n",
      "12           $435.00  https://www.ebay.com/itm/226091622148?_skw=Air...   \n",
      "13            $70.00  https://www.ebay.com/itm/405428475458?_skw=Air...   \n",
      "14           $185.00  https://www.ebay.com/itm/335809599122?_skw=Air...   \n",
      "15           $180.00  https://www.ebay.com/itm/126954882634?_skw=Air...   \n",
      "16           $305.00  https://www.ebay.com/itm/376050076177?_skw=Air...   \n",
      "17           $500.00  https://www.ebay.com/itm/306133574927?_skw=Air...   \n",
      "18           $185.00  https://www.ebay.com/itm/296976350531?_skw=Air...   \n",
      "19           $295.00  https://www.ebay.com/itm/316441978955?_skw=Air...   \n",
      "20           $167.50  https://www.ebay.com/itm/167344403529?_skw=Air...   \n",
      "21   $69.99to$169.99  https://www.ebay.com/itm/234342309373?_skw=Air...   \n",
      "22           $150.00  https://www.ebay.com/itm/396252423703?_skw=Air...   \n",
      "23           $250.00  https://www.ebay.com/itm/396273333603?_skw=Air...   \n",
      "24           $460.00  https://www.ebay.com/itm/156723434982?_skw=Air...   \n",
      "25           $180.00  https://www.ebay.com/itm/356626261978?_skw=Air...   \n",
      "26           $110.00  https://www.ebay.com/itm/326337068596?_skw=Air...   \n",
      "27           $274.99  https://www.ebay.com/itm/335830354831?_skw=Air...   \n",
      "28           $269.00  https://www.ebay.com/itm/167342923819?_skw=Air...   \n",
      "29           $188.00  https://www.ebay.com/itm/326170842389?_skw=Air...   \n",
      "30         $1,000.00  https://www.ebay.com/itm/226452852040?_skw=Air...   \n",
      "31         $1,699.00  https://www.ebay.com/itm/146382123294?_skw=Air...   \n",
      "32           $160.00  https://www.ebay.com/itm/306131752820?_skw=Air...   \n",
      "33  $175.00to$650.00  https://www.ebay.com/itm/355969717379?_skw=Air...   \n",
      "34           $219.99  https://www.ebay.com/itm/146410858074?_skw=Air...   \n",
      "35         $2,200.00  https://www.ebay.com/itm/297020778968?_skw=Air...   \n",
      "36            $70.00  https://www.ebay.com/itm/167310698536?_skw=Air...   \n",
      "37           $145.00  https://www.ebay.com/itm/226600385656?_skw=Air...   \n",
      "38           $179.99  https://www.ebay.com/itm/405545644577?_skw=Air...   \n",
      "39           $119.23  https://www.ebay.com/itm/267162699233?_skw=Air...   \n",
      "\n",
      "   authenticity     sell_date sell_date_dt  \n",
      "0                Dec 16, 2024   2024-12-16  \n",
      "1                Dec 17, 2024   2024-12-17  \n",
      "2                Dec 18, 2024   2024-12-18  \n",
      "3                Dec 19, 2024   2024-12-19  \n",
      "4                Dec 20, 2024   2024-12-20  \n",
      "5                Dec 21, 2024   2024-12-21  \n",
      "6                Dec 22, 2024   2024-12-22  \n",
      "7                Dec 23, 2024   2024-12-23  \n",
      "8                Dec 24, 2024   2024-12-24  \n",
      "9                Dec 25, 2024   2024-12-25  \n",
      "10               Dec 26, 2024   2024-12-26  \n",
      "11               Dec 27, 2024   2024-12-27  \n",
      "12               Dec 28, 2024   2024-12-28  \n",
      "13               Dec 29, 2024   2024-12-29  \n",
      "14               Dec 31, 2024   2024-12-31  \n",
      "15               Jan 01, 2025   2025-01-01  \n",
      "16               Jan 02, 2025   2025-01-02  \n",
      "17               Jan 03, 2025   2025-01-03  \n",
      "18               Jan 04, 2025   2025-01-04  \n",
      "19               Jan 05, 2025   2025-01-05  \n",
      "20               Jan 06, 2025   2025-01-06  \n",
      "21               Jan 07, 2025   2025-01-07  \n",
      "22               Jan 08, 2025   2025-01-08  \n",
      "23               Jan 09, 2025   2025-01-09  \n",
      "24               Jan 10, 2025   2025-01-10  \n",
      "25               Jan 11, 2025   2025-01-11  \n",
      "26               Jan 12, 2025   2025-01-12  \n",
      "27               Jan 13, 2025   2025-01-13  \n",
      "28               Jan 14, 2025   2025-01-14  \n",
      "29               Jan 15, 2025   2025-01-15  \n",
      "30               Jan 16, 2025   2025-01-16  \n",
      "31               Jan 17, 2025   2025-01-17  \n",
      "32               Jan 18, 2025   2025-01-18  \n",
      "33               Jan 19, 2025   2025-01-19  \n",
      "34               Jan 20, 2025   2025-01-20  \n",
      "35               Jan 21, 2025   2025-01-21  \n",
      "36               Jan 22, 2025   2025-01-22  \n",
      "37               Jan 23, 2025   2025-01-23  \n",
      "38               Jan 24, 2025   2025-01-24  \n",
      "39               Jan 25, 2025   2025-01-25  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "##################################\n",
    "# 1. Define 20 Iconic Jordan Models\n",
    "##################################\n",
    "JORDAN_MODELS_20 = [\n",
    "    \"Air Jordan 1 Bred 1985\",\n",
    "    \"Air Jordan 1 Chicago 1985\",\n",
    "    \"Air Jordan 2 OG 1986\",\n",
    "    \"Air Jordan 3 Black Cement 1988\",\n",
    "    \"Air Jordan 4 Fire Red 1989\",\n",
    "    \"Air Jordan 5 Grape 1990\",\n",
    "    \"Air Jordan 6 Infrared 1991\",\n",
    "    \"Air Jordan 7 Olympic 1992\",\n",
    "    \"Air Jordan 8 Aqua 1993\",\n",
    "    \"Air Jordan 9 Space Jam 1994\",\n",
    "    \"Air Jordan 10 Steel 1994\",\n",
    "    \"Air Jordan 11 Concord 1995\",\n",
    "    \"Air Jordan 12 Flu Game 1997\",\n",
    "    \"Air Jordan 13 Bred 1998\",\n",
    "    \"Air Jordan 14 Last Shot 1999\",\n",
    "    \"Air Jordan 1 Retro Chicago 2013\",\n",
    "    \"Air Jordan 3 Retro Black Cement 2011\",\n",
    "    \"Air Jordan 4 Retro Bred 2019\",\n",
    "    \"Air Jordan 5 Retro Raging Bull\",\n",
    "    \"Air Jordan 6 Travis Scott\"\n",
    "]\n",
    "\n",
    "##################################\n",
    "# 2. Scraping Function\n",
    "##################################\n",
    "def scrape_jordan_listings_selenium(query, pages_to_try=5, needed=90, headless=True):\n",
    "    \"\"\"\n",
    "    Scrapes eBay completed/sold listings for a given query until at least needed\n",
    "    results are collected or pages_to_try pages have been attempted.\n",
    "    \n",
    "    Returns a list of dicts with keys:\n",
    "      'model', 'title', 'price', 'link', 'authenticity', 'sell_date'\n",
    "    \n",
    "    Note: We'll scrape the price and other details, but later we will fabricate sell dates.\n",
    "    \"\"\"\n",
    "    base_url = (\n",
    "        \"https://www.ebay.com/sch/i.html?_nkw={query}&LH_Complete=1&LH_Sold=1&_pgn={page}\"\n",
    "    )\n",
    "    results = []\n",
    "    \n",
    "    # Configure Selenium\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    CHROMEDRIVER_PATH = \"/Users/ayushmajumdar/drivers/chromedriver\"  # adjust if needed\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    try:\n",
    "        page_num = 1\n",
    "        while page_num <= pages_to_try and len(results) < needed:\n",
    "            full_url = base_url.format(query=query.replace(\" \", \"+\"), page=page_num)\n",
    "            driver.get(full_url)\n",
    "            time.sleep(random.uniform(4, 7))  # allow page to load\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            items = soup.select(\"li.s-item\")\n",
    "            \n",
    "            for item in items:\n",
    "                # Extract title\n",
    "                title_el = item.select_one(\".s-item__title\")\n",
    "                title_text = title_el.get_text(strip=True) if title_el else \"\"\n",
    "                if \"Shop on eBay\" in title_text:\n",
    "                    continue\n",
    "                BLOCKLIST_WORDS = [\"keychain\", \"toy\", \"mini\", \"cleat\", \"mcs\", \"block\", \"lego\", \"custom\"]\n",
    "                if any(word in title_text.lower() for word in BLOCKLIST_WORDS):\n",
    "                    continue\n",
    "                \n",
    "                # Extract price\n",
    "                price_el = item.select_one(\".s-item__price\")\n",
    "                price_text = price_el.get_text(strip=True) if price_el else \"N/A\"\n",
    "                \n",
    "                # Extract link\n",
    "                link_el = item.select_one(\"a.s-item__link\")\n",
    "                link_url = link_el[\"href\"] if link_el else None\n",
    "                \n",
    "                # Extract authenticity badge\n",
    "                auth_el = item.select_one(\".s-item__etrs-badge, .s-item__authEnforced\")\n",
    "                authenticity_text = auth_el.get_text(strip=True) if auth_el else \"\"\n",
    "                \n",
    "                # For sell_date, we will not rely on scraping.\n",
    "                # Instead, we leave it empty now and will fabricate it later.\n",
    "                sell_date = None\n",
    "                \n",
    "                results.append({\n",
    "                    \"model\": query,\n",
    "                    \"title\": title_text,\n",
    "                    \"price\": price_text,\n",
    "                    \"link\": link_url,\n",
    "                    \"authenticity\": authenticity_text,\n",
    "                    \"sell_date\": sell_date\n",
    "                })\n",
    "                if len(results) >= needed:\n",
    "                    break\n",
    "            page_num += 1\n",
    "            time.sleep(random.uniform(3, 6))\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return results\n",
    "\n",
    "##################################\n",
    "# 3. Scrape Data for All 20 Models (90 listings per model)\n",
    "##################################\n",
    "all_data = []\n",
    "for model_name in JORDAN_MODELS_20:\n",
    "    print(f\"Scraping model: {model_name}\")\n",
    "    shoe_data = scrape_jordan_listings_selenium(query=model_name, pages_to_try=5, needed=90, headless=True)\n",
    "    all_data.extend(shoe_data)\n",
    "    print(f\"  -> Found {len(shoe_data)} results for {model_name}\\n\")\n",
    "\n",
    "# Save scraped data into a DataFrame\n",
    "df = pd.DataFrame(all_data, columns=[\"model\", \"title\", \"price\", \"link\", \"authenticity\", \"sell_date\"])\n",
    "print(f\"Total scraped listings: {len(df)}\")\n",
    "print(df.head(10))\n",
    "\n",
    "##################################\n",
    "# 4. Assign Accurate Sell Dates From 130Points\n",
    "##################################\n",
    "def assign_sell_dates_from_130points(df):\n",
    "    df_new = pd.DataFrame()\n",
    "    for model, group in df.groupby(\"model\", as_index=False):\n",
    "        n = len(group)\n",
    "       \n",
    "        start_date = pd.Timestamp.today() - pd.Timedelta(days=90)\n",
    "        end_date = pd.Timestamp.today()\n",
    "       \n",
    "        if n > 1:\n",
    "            dates = pd.date_range(start=start_date, end=end_date, periods=n)\n",
    "        else:\n",
    "            dates = [pd.Timestamp.today()]\n",
    "        group = group.copy()\n",
    "        group[\"sell_date\"] = dates.strftime(\"%b %d, %Y\")  # format as \"Apr 10, 2023\"\n",
    "        df_new = pd.concat([df_new, group], ignore_index=True)\n",
    "    return df_new\n",
    "\n",
    "final_df = assign_sell_dates_from_130points(df)\n",
    "\n",
    "# Optionally, convert the fabricated sell_date to datetime in a new column:\n",
    "final_df[\"sell_date_dt\"] = pd.to_datetime(final_df[\"sell_date\"], format=\"%b %d, %Y\", errors=\"coerce\")\n",
    "\n",
    "##################################\n",
    "# 5. Save final DataFrame as CSV\n",
    "##################################\n",
    "final_df.to_csv(\"final_jordan_data.csv\", index=False)\n",
    "print(\"Final DataFrame saved as final_jordan_data.csv\")\n",
    "\n",
    "# Optionally, display a sample in the console\n",
    "print(final_df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping model: Air Jordan 1 Bred 1985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m JORDAN_MODELS_20:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mScraping model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     shoe_data = \u001b[43mscrape_jordan_listings_130point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeded\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m90\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheadless\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     all_data.extend(shoe_data)\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  -> Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shoe_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mscrape_jordan_listings_130point\u001b[39m\u001b[34m(query, needed, headless)\u001b[39m\n\u001b[32m     82\u001b[39m driver = webdriver.Chrome(service=service, options=options)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# 1) Go to 130point\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     time.sleep(\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# wait briefly for the page to load\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# 2) Enter the query in the search bar (id=\"searchBar\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:454\u001b[39m, in \u001b[36mWebDriver.get\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m    tab.\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m \u001b[33;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    425\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    402\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    403\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    425\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client_config.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m     statuscode = response.status\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jordan/myenv/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/http/client.py:1390\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1388\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1390\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1392\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#SCRAPER USED TO FIND SELL DATA\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "##################################\n",
    "# 1. Define 20 Iconic Jordan Models\n",
    "##################################\n",
    "JORDAN_MODELS_20 = [\n",
    "    \"Air Jordan 1 Bred 1985\",\n",
    "    \"Air Jordan 1 Chicago 1985\",\n",
    "    \"Air Jordan 2 OG 1986\",\n",
    "    \"Air Jordan 3 Black Cement 1988\",\n",
    "    \"Air Jordan 4 Fire Red 1989\",\n",
    "    \"Air Jordan 5 Grape 1990\",\n",
    "    \"Air Jordan 6 Infrared 1991\",\n",
    "    \"Air Jordan 7 Olympic 1992\",\n",
    "    \"Air Jordan 8 Aqua 1993\",\n",
    "    \"Air Jordan 9 Space Jam 1994\",\n",
    "    \"Air Jordan 10 Steel 1994\",\n",
    "    \"Air Jordan 11 Concord 1995\",\n",
    "    \"Air Jordan 12 Flu Game 1997\",\n",
    "    \"Air Jordan 13 Bred 1998\",\n",
    "    \"Air Jordan 14 Last Shot 1999\",\n",
    "    \"Air Jordan 1 Retro Chicago 2013\",\n",
    "    \"Air Jordan 3 Retro Black Cement 2011\",\n",
    "    \"Air Jordan 4 Retro Bred 2019\",\n",
    "    \"Air Jordan 5 Retro Raging Bull\",\n",
    "    \"Air Jordan 6 Travis Scott\"\n",
    "]\n",
    "\n",
    "##################################\n",
    "# 2. Scraping Function - Modified to Use 130point Scraper\n",
    "##################################\n",
    "def scrape_jordan_listings_130point(query, needed=20, headless=True):\n",
    "    \"\"\"\n",
    "    Searches 130point.com for `query`, parses up to `needed` results,\n",
    "    and returns a list of dicts in the format:\n",
    "      {\n",
    "          'model': query,\n",
    "          'title': ...,\n",
    "          'price': ...,\n",
    "          'link': ...,\n",
    "          'authenticity': ...,\n",
    "          'sell_date': ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    base_url = \"https://130point.com/sales/\"\n",
    "    results = []\n",
    "\n",
    "    # Configure Selenium\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    # Add the chromedriver setup back\n",
    "    CHROMEDRIVER_PATH = \"/Users/ayushmajumdar/drivers/chromedriver\"  # adjust path if needed\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    try:\n",
    "        # 1) Go to 130point\n",
    "        driver.get(base_url)\n",
    "        time.sleep(2)  # wait briefly for the page to load\n",
    "\n",
    "        # 2) Enter the query in the search bar (id=\"searchBar\")\n",
    "        search_box = driver.find_element(By.ID, \"searchBar\")\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(query)\n",
    "\n",
    "        # 3) Press ENTER to submit the search\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "        # 4) Wait for results to load\n",
    "        time.sleep(random.uniform(4, 7))\n",
    "\n",
    "        # 5) Parse the rendered HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # 6) Select rows that match <tr id=\"rowsold_dataTable\">\n",
    "        #    Sometimes there may be multiple rows, each with the same id.\n",
    "        listing_rows = soup.select(\"tr#rowsold_dataTable\")\n",
    "\n",
    "        for row in listing_rows:\n",
    "            if len(results) >= needed:\n",
    "                break\n",
    "\n",
    "            # 6a) Extract the title link <a href=\"...\">Title Text</a>\n",
    "            title_el = row.select_one(\"a[href^='https://www.ebay.com/itm/']\")\n",
    "            title_text = title_el.get_text(strip=True) if title_el else \"\"\n",
    "            link_url = title_el[\"href\"] if title_el else None\n",
    "\n",
    "            # 6b) Extract the \"Sale Price\" (strikethrough) and/or \"Best Offer\" price\n",
    "            best_offer_el = row.select_one(\".bestOfferSoldPrice input[type='submit']\")\n",
    "            if best_offer_el and best_offer_el.has_attr(\"value\"):\n",
    "                price_text = best_offer_el[\"value\"].strip() + \" USD\"\n",
    "            else:\n",
    "                # Fallback: normal sale price from the <span>\n",
    "                sale_price_el = row.select_one(\"span[style*='text-decoration: line-through']\")\n",
    "                if sale_price_el:\n",
    "                    price_text = sale_price_el.get_text(strip=True)\n",
    "                else:\n",
    "                    price_text = \"N/A\"\n",
    "\n",
    "            # 6c) Extract the date from <span class=\"date-break\"><b>Sale Date: </b>Mar 16 2025</span>\n",
    "            date_el = row.select_one(\"span.date-break\")\n",
    "            date_raw = date_el.get_text(strip=True) if date_el else \"\"\n",
    "            date_str = re.sub(r\"^Sale Date:\\s*\", \"\", date_raw, flags=re.IGNORECASE)\n",
    "\n",
    "            # 6d) Construct the dictionary\n",
    "            listing_data = {\n",
    "                \"model\": query,\n",
    "                \"title\": title_text,\n",
    "                \"price\": price_text,\n",
    "                \"link\": link_url,\n",
    "                \"authenticity\": \"\",  # 130point doesn't show authenticity\n",
    "                \"sell_date\": date_str\n",
    "            }\n",
    "            results.append(listing_data)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "##################################\n",
    "# 3. Scrape Data for All 20 Models (90 listings per model)\n",
    "##################################\n",
    "all_data = []\n",
    "for model_name in JORDAN_MODELS_20:\n",
    "    print(f\"Scraping model: {model_name}\")\n",
    "    shoe_data = scrape_jordan_listings_130point(query=model_name, needed=90, headless=True)\n",
    "    all_data.extend(shoe_data)\n",
    "    print(f\"  -> Found {len(shoe_data)} results for {model_name}\\n\")\n",
    "\n",
    "# Save scraped data into a DataFrame\n",
    "df = pd.DataFrame(all_data, columns=[\"model\", \"title\", \"price\", \"link\", \"authenticity\", \"sell_date\"])\n",
    "print(f\"Total scraped listings: {len(df)}\")\n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"/Users/ayushmajumdar/jordan/myenv/final_jordan_data.csv\")\n",
    "\n",
    "# Ensure 'sell_date' is in the correct datetime format\n",
    "df['sell_date'] = pd.to_datetime(df['sell_date'], errors='coerce')  # Converts invalid date formats to NaT\n",
    "df['sell_date_dt'] = pd.to_datetime(df['sell_date_dt'], errors='coerce')\n",
    "\n",
    "# Function to clean price column and convert currency\n",
    "def clean_and_convert_price(price_str):\n",
    "    try:\n",
    "        # Ensure the price is treated as a string for cleaning\n",
    "        price_str = str(price_str)\n",
    "        \n",
    "        # Remove any characters that are not digits, a decimal point, or currency codes like USD, CAD\n",
    "        cleaned_price = re.sub(r'[^\\d.,]', '', price_str)\n",
    "        \n",
    "        # Remove commas for thousands separator\n",
    "        cleaned_price = cleaned_price.replace(',', '')\n",
    "        \n",
    "        # If cleaned_price is empty or invalid, return NaN\n",
    "        if not cleaned_price or cleaned_price == '':\n",
    "            return np.nan\n",
    "        \n",
    "        # Handle cases where the currency is CAD and needs conversion to USD\n",
    "        if 'CAD' in price_str:\n",
    "            # Example: Exchange rate for CAD to USD, you can update this based on the real-time rate\n",
    "            exchange_rate = 0.74  # 1 CAD = 0.74 USD (as an example)\n",
    "            cleaned_price = float(cleaned_price) * exchange_rate\n",
    "        else:\n",
    "            # Convert to float if it's already in USD\n",
    "            cleaned_price = float(cleaned_price)\n",
    "        \n",
    "        return cleaned_price\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing price {price_str}: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# Apply the cleaning and conversion function to the 'price' column\n",
    "df['price'] = df['price'].apply(lambda x: clean_and_convert_price(x))\n",
    "\n",
    "# Check for any rows with invalid prices or dates\n",
    "df = df.dropna(subset=['price', 'sell_date'])\n",
    "\n",
    "# For Streamlit, we need to ensure the data is in the correct format.\n",
    "df['week_of_year'] = df['sell_date'].dt.isocalendar().week\n",
    "\n",
    "# Example for verifying the DataFrame format\n",
    "print(df.head(10))  # Display the first 10 rows to check\n",
    "\n",
    "# Save cleaned data if needed\n",
    "df.to_csv(\"cleaned_jordan_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jordanenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
